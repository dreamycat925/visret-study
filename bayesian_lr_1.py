import pymc as pm
import numpy as np
import pandas as pd
import arviz as az
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

# ðŸ”¹ NumPy ã®ãƒ©ãƒ³ãƒ€ãƒ ã‚·ãƒ¼ãƒ‰ã‚’è¨­å®šï¼ˆPyMC ã®ãƒ©ãƒ³ãƒ€ãƒ æ€§ã«ã‚‚å½±éŸ¿ï¼‰
np.random.seed(42)

# èª¬æ˜Žå¤‰æ•°
X = df_com[df_com['group'] == 'hs'][['æ¤œæŸ»æ™‚ã®å¹´é½¢', 'æ€§åˆ¥', 'æ•™è‚²æ­´', 'çµµã®å†èªèª²é¡Œ_ç‚¹æ•°', 'çµµã®å†èªèª²é¡Œ_è™šå†èªã®æ•°']].copy()

# ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
X = pd.get_dummies(X, columns=['æ€§åˆ¥'], drop_first=True, dtype=int) 

# ç›®çš„å¤‰æ•°
y = (df_com['group'] == 'ci').astype(int).values  

# æ¨™æº–åŒ–
scaler = StandardScaler()
num_cols = ['æ¤œæŸ»æ™‚ã®å¹´é½¢', 'æ•™è‚²æ­´', 'çµµã®å†èªèª²é¡Œ_ç‚¹æ•°', 'çµµã®å†èªèª²é¡Œ_è™šå†èªã®æ•°']  # æ¨™æº–åŒ–å¯¾è±¡ã®æ•°å€¤ã‚«ãƒ©ãƒ 
X[num_cols] = scaler.fit_transform(X[num_cols])

# âœ… ãƒ™ã‚¤ã‚ºç·šå½¢å›žå¸°ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰ï¼ˆæ¨™æº–åŒ–å¾Œã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
with pm.Model() as model:
    beta_0 = pm.Normal("beta_0", mu=0, sigma=1)
    beta_edu = pm.Normal("beta_edu", mu=0, sigma=1)
    beta_gender = pm.Normal("beta_gender", mu=0, sigma=1)
    beta_false_recog = pm.Normal("beta_false_recog", mu=0, sigma=1)
    beta_age = pm.Normal("beta_age", mu=0, sigma=1)

    # âœ… å›žå¸°å¼ï¼ˆã™ã¹ã¦ã®ãƒ‡ãƒ¼ã‚¿ã«åŒã˜ä¿‚æ•°ã‚’é©ç”¨ï¼‰
    mu = (
        beta_0
        + beta_age * X["æ¤œæŸ»æ™‚ã®å¹´é½¢"]
        + beta_edu * X["æ•™è‚²æ­´"]
        + beta_gender * X["æ€§åˆ¥_ç”·"]  # æ€§åˆ¥ã¯ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã—ã¦ã„ãªã„
        + beta_false_recog * X["çµµã®å†èªèª²é¡Œ_è™šå†èªã®æ•°"]
    )

    sigma = pm.HalfNormal("sigma", sigma=1)
    y_obs = pm.Normal("y_obs", mu=mu, sigma=sigma, observed=X["çµµã®å†èªèª²é¡Œ_ç‚¹æ•°"])

    # âœ… MCMCã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    trace = pm.sample(2000, tune=1000, return_inferencedata=True, idata_kwargs={"log_likelihood": True})

# âœ… äº‹å¾Œåˆ†å¸ƒã®å¯è¦–åŒ–
az.plot_posterior(trace, var_names=["beta_false_recog", "beta_age", "beta_edu", "beta_gender"])
plt.show()

# äº‹å¾Œåˆ†å¸ƒã®è¦ç´„
summary = az.summary(trace, stat_funcs={"median": np.median}, hdi_prob=0.95)
print(summary)

print('')

# äº‹å¾Œç¢ºçŽ‡ã‚’è¨ˆç®—
def compute_posterior_probabilities(trace, param):
    """äº‹å¾Œç¢ºçŽ‡ã‚’æ±‚ã‚ã‚‹"""
    samples = trace.posterior[param].values.flatten()
    prob_positive = (samples > 0).mean()
    prob_negative = (samples < 0).mean()
    return prob_positive, prob_negative

print("\näº‹å¾Œç¢ºçŽ‡:")
for param in ["beta_age", "beta_edu", "beta_gender", "beta_false_recog"]:
    p_pos, p_neg = compute_posterior_probabilities(trace, param)
    print(f"{param}: P(Î² > 0) = {p_pos:.3f}, P(Î² < 0) = {p_neg:.3f}")

def memory_score(score, edu, false_recog, trace):
    return score + (az.summary(trace, stat_funcs={"median": np.median}).loc['beta_edu', 'median'] * edu) + (az.summary(trace, stat_funcs={"median": np.median}).loc['beta_false_recog', 'median'] * false_recog)
